{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV5zSe3KqQxb"
   },
   "source": [
    "# הגדרת סביבת העבודה  \n",
    "- ייבוא ספריות חיוניות  \n",
    "- הפעלת אופטימיזציה (XLA ו־mixed precision)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21040,
     "status": "ok",
     "timestamp": 1745273795168,
     "user": {
      "displayName": "AI Adventures",
      "userId": "06384775953821374841"
     },
     "user_tz": -180
    },
    "id": "hBGPZdt-I6Mk",
    "outputId": "8bae331e-9eb2-476a-d742-1278097193a7"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9jS2EK35bjH0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization, Dropout, GlobalAveragePooling2D, GlobalMaxPool2D\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfFrPASh94g1"
   },
   "outputs": [],
   "source": [
    "# Fix random seeds to ensure reproducible results across runs\n",
    "random.seed(42)         # Python’s built-in random module\n",
    "np.random.seed(42)      # NumPy’s random number generator\n",
    "tf.random.set_seed(42)  # TensorFlow’s random operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1745273801330,
     "user": {
      "displayName": "AI Adventures",
      "userId": "06384775953821374841"
     },
     "user_tz": -180
    },
    "id": "gzos4qIELgh_",
    "outputId": "7eda09ac-fe2e-4403-f1ae-cbd2f8e136d6"
   },
   "outputs": [],
   "source": [
    "# Show which GPUs TensorFlow can access\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Turn on XLA (Accelerated Linear Algebra) JIT compilation for potential speedups\n",
    "tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# Use mixed-precision training (float16) globally to accelerate on compatible GPUs\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TUZzNc3riho"
   },
   "source": [
    "# הכנת מערך הנתונים  \n",
    "- איסוף נתיבי קבצי התמונות והתוויות המתאימות  \n",
    "- ספירת תמונות לכל גזע ובדיקת שאין תיקיות ריקות  \n",
    "- יצירת DataFrame של זוגות (נתיב קובץ, תווית)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jfm5iVmVp1lf"
   },
   "outputs": [],
   "source": [
    "# Dataset dir; target shape = (224, 224, 3)\n",
    "IMAGES_DIR = '/content/drive/Othercomputers/My Mac/Desktop/Stanford_Dogs/Images'\n",
    "img_width, img_height = 224, 224\n",
    "channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k8eeU1-OM2pa"
   },
   "outputs": [],
   "source": [
    "# Build lists of all image file paths and their labels; also record image count per breed\n",
    "filepaths, labels = [], []\n",
    "images_per_breed = {}\n",
    "\n",
    "for folder in os.listdir(IMAGES_DIR):\n",
    "    breed_path = os.path.join(IMAGES_DIR, folder)\n",
    "    # Skip non-directory entries (e.g., hidden files)\n",
    "    if not os.path.isdir(breed_path):\n",
    "        continue\n",
    "\n",
    "    # Folder names are like \"n02102040-english_setter\"; take text after the first dash as the label\n",
    "    label = folder.split('-', 1)[1]\n",
    "    # Count images in this breed’s folder for data inspection/validation\n",
    "    images_per_breed[label] = len(os.listdir(breed_path))\n",
    "\n",
    "    # Append each image’s full path and its corresponding label\n",
    "    for img in os.listdir(breed_path):\n",
    "        filepaths.append(os.path.join(breed_path, img))\n",
    "        labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745237034799,
     "user": {
      "displayName": "AI Adventures",
      "userId": "06384775953821374841"
     },
     "user_tz": -180
    },
    "id": "F-rKdBjWiIAa",
    "outputId": "bfe6f160-1ea5-4609-9624-6c605774aee9"
   },
   "outputs": [],
   "source": [
    "# check all labels\n",
    "assert len(images_per_breed) == 120, (f'There are {len(images_per_breed)}/120 breed folders.')\n",
    "print('All breed folders are present!')\n",
    "\n",
    "# check images count\n",
    "no_images = dict(filter(lambda item: item[1] == 0, images_per_breed.items())) # dict only with images that have no labels\n",
    "assert len(no_images) == 0, (\n",
    "    f'There are {len(no_images)}/120 empty breed folders. \\nlabels of the missing images: {[item[0] for item in no_images.items()]}'\n",
    "    )\n",
    "print('All images are in their correct folders!')\n",
    "print(\"There is no missing data!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kC3FJYK8kkgJ"
   },
   "outputs": [],
   "source": [
    "# List all recorded breed labels (keys of images_per_breed)\n",
    "list(images_per_breed.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMztnBaKM395"
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame pairing each image file path with its breed label\n",
    "df = pd.DataFrame({'filepath': filepaths, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RCwIBAxmNS5m"
   },
   "outputs": [],
   "source": [
    "# split the dataframe into train and test sets with a ration of 80/20\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['label'], # keep the disribution between train and test sets.\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVaqQPpnOXdx"
   },
   "outputs": [],
   "source": [
    "# Build the class‐name list and mapping\n",
    "class_names    = sorted(train_df['label'].unique())\n",
    "label_to_index = {name: idx for idx, name in enumerate(class_names)}\n",
    "\n",
    "# Add an integer column for each split\n",
    "train_df['label_idx'] = train_df['label'].map(label_to_index)\n",
    "val_df  ['label_idx'] = val_df  ['label'].map(label_to_index)\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(class_names)   # should be 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vklkbESpLJlX"
   },
   "outputs": [],
   "source": [
    "def make_dataset(df, batch_size, num_classes, training=True):\n",
    "    # Get file paths and integer labels\n",
    "    paths  = df['filepath'].values\n",
    "    labels = df['label_idx'].values.astype('int32')\n",
    "\n",
    "    # Build initial Dataset\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    # Define load & preprocess function\n",
    "    def _load_and_preprocess(path, label):\n",
    "        # Read image from disk\n",
    "        image = tf.io.read_file(path)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [img_height, img_width]) / 255.0\n",
    "\n",
    "        if training:\n",
    "            image = tf.image.random_flip_left_right(image)\n",
    "            image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "            image = tf.image.random_contrast(image, 0.9, 1.1)\n",
    "\n",
    "        # Convert label to one-hot\n",
    "        label = tf.one_hot(label, depth=num_classes)\n",
    "        return image, label\n",
    "\n",
    "    # Apply preprocessing in parallel\n",
    "    ds = ds.map(_load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    # (Optional) Shuffle if training\n",
    "    if training:\n",
    "        ds = ds.shuffle(buffer_size=1024)\n",
    "\n",
    "    # Batch, cache in RAM, and prefetch for performance\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.cache()\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUpN6a2Tr26Q"
   },
   "source": [
    "# הגדרת המודל ובחירת רשת בסיס  \n",
    "- טעינת רשתות טרנספר מוכרות   \n",
    "- בניית והוספת ראש מיוחד\n",
    "- אימון המודל ושוואת ארכיתכטורות הבסיס השונות בעזרת לולאה\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nxjr_7EUxgpV"
   },
   "outputs": [],
   "source": [
    "def build_base(network):\n",
    "    # Load pretrained network (without final classifier) as feature extractor\n",
    "    base = network(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base.trainable = False       # Freeze base layers during initial training\n",
    "    return base\n",
    "\n",
    "def build_head(base):\n",
    "    # Add a global pooling layer to collapse spatial dimensions\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "\n",
    "    # First fully connected block\n",
    "    x = Dense(512, kernel_regularizer=l2(1e-4))(x)  # 512 units with L2 regularization\n",
    "    x = BatchNormalization()(x)                     # Normalize activations\n",
    "    x = Activation('relu')(x)                       # Non-linear activation\n",
    "    x = Dropout(0.5)(x)                             # Drop 50% to reduce overfitting\n",
    "\n",
    "    # Second fully connected block\n",
    "    x = Dense(256, kernel_regularizer=l2(1e-4))(x)  # 256 units with L2 regularization\n",
    "    x = BatchNormalization()(x)                     # Normalize activations\n",
    "    x = Activation('relu')(x)                       # Non-linear activation\n",
    "    x = Dropout(0.5)(x)                             # Drop 50% to reduce overfitting\n",
    "\n",
    "    # Final softmax layer for 120 dog breed classes\n",
    "    head = Dense(120, activation='softmax')(x)\n",
    "    return Model(inputs=base.input, outputs=head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYpwGHunQQmw"
   },
   "outputs": [],
   "source": [
    "# Pretrained CNN architectures for transfer learning\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oK_4DC31Ti-t"
   },
   "outputs": [],
   "source": [
    "lr = 1e-04\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 567825,
     "status": "ok",
     "timestamp": 1745198849782,
     "user": {
      "displayName": "AI Adventures",
      "userId": "06384775953821374841"
     },
     "user_tz": -180
    },
    "id": "Axb4a6e3rmnz",
    "outputId": "296ba595-215f-437e-8e1d-af1ff4091ac1"
   },
   "outputs": [],
   "source": [
    "# Train and compare models using different pretrained bases\n",
    "results = []\n",
    "base_networks = {\n",
    "    'Xception': Xception,\n",
    "    'InceptionV3': InceptionV3,\n",
    "    'InceptionResNetV2': InceptionResNetV2\n",
    "}\n",
    "\n",
    "for base_name, base_network in base_networks.items():\n",
    "    tf.keras.backend.clear_session()  # Reset state between runs\n",
    "\n",
    "    # Prepare training and validation datasets\n",
    "    train_ds = make_dataset(train_df, batch_size, num_classes, training=True)\n",
    "    val_ds   = make_dataset(val_df,   batch_size, num_classes, training=False)\n",
    "\n",
    "    # Determine how many steps per epoch\n",
    "    steps_per_epoch   = math.ceil(len(train_df) / batch_size)\n",
    "    validation_steps  = math.ceil(len(val_df)   / batch_size)\n",
    "\n",
    "    # Build the model: frozen base + custom head\n",
    "    model = build_head(build_base(base_network))\n",
    "\n",
    "    # Compile with Adam & smoothed categorical crossentropy\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=lr),\n",
    "        loss=CategoricalCrossentropy(label_smoothing=0.05),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(f'Training Network with Base: {base_name}')\n",
    "    print('-' * 40)\n",
    "\n",
    "    # Train for a fixed number of epochs\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=10,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=validation_steps,\n",
    "    )\n",
    "\n",
    "    # Store each model's config, weights, and training history\n",
    "    results.append({\n",
    "        'base':    base_name,\n",
    "        'weights': model.get_weights(),\n",
    "        'config':  model.to_json(),\n",
    "        'history': history.history\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAvg6ZQjLn-m"
   },
   "outputs": [],
   "source": [
    "def comp_dash(results):\n",
    "    # Compile each model’s validation loss per epoch into a list of records\n",
    "    records_loss = []\n",
    "    for result in results:\n",
    "        for ep, val_loss in enumerate(result['history']['val_loss'], start=1):\n",
    "            records_loss.append({\n",
    "                'Epoch': ep,\n",
    "                'Validation Loss': val_loss,\n",
    "                'Model': result['base']\n",
    "            })\n",
    "    # Create DataFrame for plotting\n",
    "    df_loss = pd.DataFrame(records_loss)\n",
    "\n",
    "    # Set plot style and initialize figure\n",
    "    sns.set_style('darkgrid')\n",
    "    fig, ax = plt.subplots(figsize=(9, 4), dpi=300)\n",
    "\n",
    "    # Draw lineplot of validation loss over epochs for each model\n",
    "    sns.lineplot(\n",
    "        data=df_loss,\n",
    "        x='Epoch', y='Validation Loss',\n",
    "        hue='Model', palette='Set2',\n",
    "        marker='o', ax=ax\n",
    "    )\n",
    "    ax.set_title('Validation Loss per Epoch')\n",
    "    ax.legend(\n",
    "        title='Model',\n",
    "        fontsize='small',\n",
    "        loc='upper right',\n",
    "        bbox_to_anchor=(1.05, 1)\n",
    "    )\n",
    "\n",
    "    # Adjust layout and display the chart\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "executionInfo": {
     "elapsed": 1147,
     "status": "ok",
     "timestamp": 1745198850985,
     "user": {
      "displayName": "AI Adventures",
      "userId": "06384775953821374841"
     },
     "user_tz": -180
    },
    "id": "ObLnRYcIQUt6",
    "outputId": "1c80a2d5-0f05-41aa-97c6-e549b875484b"
   },
   "outputs": [],
   "source": [
    "comp_dash(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ddReZJpm6hi"
   },
   "source": [
    "# המשך אימון הראש\n",
    "- לקיחת הבסיס האופטימלי\n",
    "- המשך אימון של ראש הרשת\n",
    "- הוספת עצירה מוקדמת וצ׳קפוינט"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FarzNEsHxNDU"
   },
   "outputs": [],
   "source": [
    "# Rebuild the InceptionResNetV2 model from saved JSON config and weights\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# Find the result entry corresponding to InceptionResNetV2\n",
    "entry = next(r for r in results if r['base'] == 'InceptionResNetV2')\n",
    "\n",
    "# Load model architecture from JSON string\n",
    "inceptionresnet = model_from_json(entry['config'])\n",
    "\n",
    "# Assign the trained weights to the model\n",
    "inceptionresnet.set_weights(entry['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrvYaFcvSyG4"
   },
   "outputs": [],
   "source": [
    "# add early-stopping to prevent overfit at high epoch:\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Save best model weights:\n",
    "checkpoint1 = ModelCheckpoint(\n",
    "    'model_rs_results.weights.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199470,
     "status": "ok",
     "timestamp": 1745199053263,
     "user": {
      "displayName": "AI Adventures",
      "userId": "06384775953821374841"
     },
     "user_tz": -180
    },
    "id": "nhK7_pcj4CNA",
    "outputId": "32206872-daf5-4166-8ac6-22fd8143b814"
   },
   "outputs": [],
   "source": [
    "# Prepare training and validation datasets\n",
    "train_ds = make_dataset(train_df, batch_size, num_classes, training=True)\n",
    "val_ds   = make_dataset(val_df,   batch_size, num_classes, training=False)\n",
    "\n",
    "# Calculate how many batches per epoch for both sets\n",
    "steps_per_epoch   = math.ceil(len(train_df) / batch_size)\n",
    "validation_steps  = math.ceil(len(val_df)   / batch_size)\n",
    "\n",
    "# Fine-tune the loaded InceptionResNetV2 model\n",
    "# – Train for up to 10 epochs\n",
    "# – Use early stopping to halt on no validation improvement\n",
    "# – Save best weights via checkpoint callback\n",
    "history = inceptionresnet.fit(\n",
    "    train_ds,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPHwkp2YOsLE"
   },
   "outputs": [],
   "source": [
    "# Plot training vs. validation accuracy over epochs; mark when the model was saved and optionally save the figure\n",
    "def plot_acc(history, save_epoch=None, save_path=None):\n",
    "    sns.set_style('darkgrid')\n",
    "    epochs = range(1, len(history['accuracy']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(9, 4), dpi=300)\n",
    "\n",
    "    # Draw vertical line at the epoch where the model was saved\n",
    "    if save_epoch:\n",
    "        plt.axvline(x=save_epoch, linestyle='--', color='gray', alpha=0.6, label='Model Saved')\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    sns.lineplot(x=epochs, y=history['accuracy'], label='Training', marker='o')\n",
    "    sns.lineplot(x=epochs, y=history['val_accuracy'], label='Validation', marker='o')\n",
    "\n",
    "    plt.title('Training vs. Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot to file if a path is provided\n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcjl626SndIV"
   },
   "outputs": [],
   "source": [
    "# Merge original training history with fine-tuning history (run only once)\n",
    "concat_hist = {k: [] for k in history.history.keys()}\n",
    "\n",
    "for key in concat_hist:\n",
    "    # Append metrics from the initial pre-fine-tuning run\n",
    "    concat_hist[key].extend(entry['history'][key])\n",
    "\n",
    "    # Append metrics from the subsequent fine-tuning run\n",
    "    concat_hist[key].extend(history.history[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1745199172254,
     "user": {
      "displayName": "AI Adventures",
      "userId": "06384775953821374841"
     },
     "user_tz": -180
    },
    "id": "NQ2Az4c817vI",
    "outputId": "9cf962c0-37ee-4cce-a71e-b083b01fb192"
   },
   "outputs": [],
   "source": [
    "plot_acc(concat_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkr3qyZTPXiB"
   },
   "source": [
    "# הפשרת הבסיס וכיונון עדין של המודל\n",
    "- טעינת המודל מהצ׳אקפוינט האחרון\n",
    "- הוספת מיתון קצב למידה\n",
    "- הפשרת 75 שכבות מהלמעלה של מודל הבסיס"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_5VOu9pSYKe"
   },
   "outputs": [],
   "source": [
    "trainable_layers = 75\n",
    "lr = 1e-6\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHq2UDYwBejm"
   },
   "outputs": [],
   "source": [
    "prev_name = 'model_rs_results.weights.h5'\n",
    "HOME_PATH = '/content/drive/MyDrive/Machine Learning Projects/Dog Breed classification project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yX1nlsAPxVsv"
   },
   "outputs": [],
   "source": [
    "# Filename for saving the fine-tuned model, including number of trainable layers and LR\n",
    "log_name = f'model_ft_results(layers={trainable_layers}, lr={lr}).keras'\n",
    "\n",
    "# Stop training if val_loss doesn’t improve by ≥1e-4 for 4 epochs\n",
    "early_stop2 = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=4,\n",
    "    min_delta=1e-4,\n",
    "    restore_best_weights=False,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Save the best model based on highest val_accuracy to HOME_PATH + log_name\n",
    "checkpoint2 = ModelCheckpoint(\n",
    "    HOME_PATH + log_name,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Halve the learning rate if val_loss doesn’t improve for 2 epochs, down to at least 1e-7\n",
    "lr_reduce_on_plateau = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    min_lr=1e-7,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQYjlT6uTbu7"
   },
   "outputs": [],
   "source": [
    "# Prepare TF datasets for training & validation, then compute batch counts per epoch\n",
    "train_ds = make_dataset(train_df, batch_size, num_classes, training=True)\n",
    "val_ds   = make_dataset(val_df,   batch_size, num_classes, training=False)\n",
    "\n",
    "# Number of steps (batches) per epoch for training and validation\n",
    "steps_per_epoch   = math.ceil(len(train_df) / batch_size)\n",
    "validation_steps  = math.ceil(len(val_df)   / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 251659,
     "status": "ok",
     "timestamp": 1745251726314,
     "user": {
      "displayName": "AI Adventures",
      "userId": "06384775953821374841"
     },
     "user_tz": -180
    },
    "id": "8qqo-qNiOyfi",
    "outputId": "e6e4240a-e3f0-4efc-8853-18f590fb945c"
   },
   "outputs": [],
   "source": [
    "# Fine-tune the top layers of InceptionResNetV2:\n",
    "# – Rebuild model head+base and load pretrained weights\n",
    "# – Unfreeze last `trainable_layers` for gradient updates\n",
    "# – Recompile and train with early stopping & LR reduction\n",
    "inceptionresnet = build_head(build_base(InceptionResNetV2))\n",
    "inceptionresnet.load_weights(HOME_PATH + prev_name)\n",
    "\n",
    "for layer in inceptionresnet.layers[-trainable_layers:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "inceptionresnet.compile(\n",
    "    optimizer=Adam(learning_rate=lr),\n",
    "    loss=CategoricalCrossentropy(label_smoothing=0.05),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f'Unfrozen Layers (top) = {trainable_layers}')\n",
    "print('-' * 30)\n",
    "\n",
    "fine_tuning_history = inceptionresnet.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stop, lr_reduce_on_plateau]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHWAjjBHBaXl"
   },
   "outputs": [],
   "source": [
    "# Save the fine-tuned InceptionResNetV2 model (architecture + weights) to disk\n",
    "inceptionresnet.save(HOME_PATH + log_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xft4XlGDmEwo"
   },
   "outputs": [],
   "source": [
    "# Set filename & path for the accuracy plot; find the 1-based epoch with lowest validation accuracy\n",
    "plot_name = f'training_val_accuracy(layers={trainable_layers}, lr={lr}).png'\n",
    "plot_path = HOME_PATH + plot_name\n",
    "save_epoch = np.argmin(fine_tuning_history.history['val_accuracy']) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 861,
     "status": "ok",
     "timestamp": 1745251927713,
     "user": {
      "displayName": "AI Adventures",
      "userId": "06384775953821374841"
     },
     "user_tz": -180
    },
    "id": "bEnOw4R5c6hK",
    "outputId": "216bf645-46f0-4f52-c7cb-d37f86c2aa54"
   },
   "outputs": [],
   "source": [
    "plot_acc(fine_tuning_history.history, save_epoch=10, save_path=plot_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rF39PKi4uCe4"
   },
   "source": [
    "# מיצוי אפוקים אחרונים לפני שמירת המודל הסופי\n",
    "- המשכת תהליך האימון עד לסופו\n",
    "- שמירת המודל הסופי"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiLugEtjJjYx"
   },
   "outputs": [],
   "source": [
    "# Initialize a merged history dict (run once!) and copy over existing fine-tuning metrics\n",
    "concat_versions_hist = {k: [] for k in fine_tuning_history.history.keys()}\n",
    "for key in concat_versions_hist:\n",
    "    concat_versions_hist[key].extend(fine_tuning_history.history[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NcSK_U_dN9x8"
   },
   "outputs": [],
   "source": [
    "# Start model save version counter at 1\n",
    "ver = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjarsUqSJ4nX"
   },
   "outputs": [],
   "source": [
    "# Set new Hyper-parameters for Final Epochs\n",
    "batch_size = 64\n",
    "epochs = 4\n",
    "lr = 1e-06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vERHYN2FSZ3_"
   },
   "outputs": [],
   "source": [
    "train_ds = make_dataset(train_df, batch_size, num_classes, training=True)\n",
    "val_ds = make_dataset(val_df,   batch_size, num_classes, training=False)\n",
    "\n",
    "steps_per_epoch = math.ceil(len(train_df) / batch_size)\n",
    "validation_steps = math.ceil(len(val_df) / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 175470,
     "status": "error",
     "timestamp": 1745254903247,
     "user": {
      "displayName": "AI Adventures",
      "userId": "06384775953821374841"
     },
     "user_tz": -180
    },
    "id": "mz_SktonIaAC",
    "outputId": "2b1c631c-8189-42fc-eb85-da339b560f37"
   },
   "outputs": [],
   "source": [
    "# Load the previously saved model and unfreeze its top layers for fine-tuning\n",
    "inceptionresnet = load_model(HOME_PATH + log_name)\n",
    "for layer in inceptionresnet.layers[-trainable_layers:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile with the chosen optimizer, loss, and metric\n",
    "inceptionresnet.compile(\n",
    "    optimizer=Adam(learning_rate=lr),\n",
    "    loss=CategoricalCrossentropy(label_smoothing=0.05),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f'Unfrozen Layers (top) = {trainable_layers}')\n",
    "print('-' * 30)\n",
    "\n",
    "# Fine-tune the model on our data\n",
    "fine_tuning_history = inceptionresnet.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Prompt to save the new version; if yes, bump version, merge histories, and save\n",
    "ans = input('save this model [y/n]: ')\n",
    "if ans.lower() == 'y':\n",
    "    ver += 1\n",
    "    for key in concat_versions_hist:\n",
    "        concat_versions_hist[key].extend(fine_tuning_history.history[key])\n",
    "    inceptionresnet.save(HOME_PATH + log_name + f'v{ver}')\n",
    "    print('Saved: ' + log_name + f'v{ver}')\n",
    "else:\n",
    "    # Discard session if not saving\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 787,
     "status": "ok",
     "timestamp": 1745255510615,
     "user": {
      "displayName": "AI Adventures",
      "userId": "06384775953821374841"
     },
     "user_tz": -180
    },
    "id": "7AIhUPxyJM6e",
    "outputId": "c1abc481-0027-471e-e3dc-ca5c2c0a3106"
   },
   "outputs": [],
   "source": [
    "# Path to save the combined accuracy plot (version 2)\n",
    "perf_image_path = \"/content/drive/MyDrive/Machine Learning Projects/Dog Breed classification project/model_ft_results(layers=75, lr=1e-06)v2.png\"\n",
    "\n",
    "# Plot training vs. validation accuracy from concat_versions_hist, mark epoch 14, and save to perf_image_path\n",
    "plot_acc(concat_versions_hist, save_epoch=14, save_path=perf_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vd3tqVwCTRHC"
   },
   "outputs": [],
   "source": [
    "# Set filepath for the current version and save the fine-tuned model there\n",
    "new_path = HOME_PATH + log_name + f'v{ver}'\n",
    "inceptionresnet.save(new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XO-J51PrS5Wh"
   },
   "source": [
    "# יצוא המודל הסופי לגרסא קלה יותר\n",
    "- TFLite Convertor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAgOLiBXS4w6"
   },
   "outputs": [],
   "source": [
    "# Load a saved .keras model from disk (without recompiling)\n",
    "model_path = \"/content/drive/Othercomputers/My Mac/Desktop/Dog Classification Project/Deploy Model/model_ft_results(layers=75, lr=1e-06)v2.keras\"\n",
    "model = tf.keras.models.load_model(model_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SZBNUl0T-vP"
   },
   "outputs": [],
   "source": [
    "# Initialize a TFLite converter from the loaded Keras model\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Enable both standard TFLite ops and TensorFlow fallback (Flex) ops\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # core TFLite operations\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS     # TensorFlow ops fallback\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xtthg9V6ULQq"
   },
   "outputs": [],
   "source": [
    "# Convert the loaded Keras model to a TensorFlow Lite flatbuffer\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Define where to save the TFLite file\n",
    "save_dir  = \"/content/drive/Othercomputers/My Mac/Desktop/Dog Classification Project/Deploy Model/\"\n",
    "model_name = \"deploy_model.tflite\"\n",
    "file_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Write the TFLite model to disk\n",
    "with open(file_path, \"wb\") as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"Saved TFLite model\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOFcJBYm9Y27fWSj9fOVk7t",
   "collapsed_sections": [
    "sV5zSe3KqQxb",
    "2TUZzNc3riho",
    "kUpN6a2Tr26Q",
    "-ddReZJpm6hi",
    "rF39PKi4uCe4"
   ],
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1XgxZ6afH-j79XyhH3M7AhKKCtmQw2E2X",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
